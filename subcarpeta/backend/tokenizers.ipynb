{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (3.8.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (3.7.5)\n",
      "Requirement already satisfied: stanza in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (1.8.2)\n",
      "Requirement already satisfied: click in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (70.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: emoji in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (2.12.1)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (5.27.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (3.3)\n",
      "Requirement already satisfied: toml in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (0.10.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (2.3.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (3.15.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (1.12.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.3.0->stanza) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.3.0->stanza) (2021.12.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yesenia\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk spacy stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¿Cuanto', 'tiempo', 'ha', 'pasado', 'desde', 'que', 'iniciamos', 'clase?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tk = WhitespaceTokenizer()\n",
    "texto = \"¿Cuanto tiempo ha pasado desde que iniciamos clase?\"\n",
    "tokenizado = tk.tokenize(texto)\n",
    "print(tokenizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¿', 'Cuanto', 'tiempo', 'ha', 'pasado', 'desde', 'que', 'iniciamos', 'clase', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tk = WordPunctTokenizer()\n",
    "texto = \"¿Cuanto tiempo ha pasado desde que iniciamos clase?\"\n",
    "tokenizado = tk.tokenize(texto)\n",
    "print(tokenizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¿Cuanto', 'tiempo', 'ha', 'pasado', 'desde', 'que', 'iniciamos', 'clase', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tk = TreebankWordTokenizer()\n",
    "texto = \"¿Cuanto tiempo ha pasado desde que iniciamos clase?\"\n",
    "tokenizado = tk.tokenize(texto)\n",
    "\n",
    "print(tokenizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Los', 'gatos', 'son', 'animales', 'domésticos', 'muy', 'populares.'],\n",
       "  ['Los', 'gatos', 'son', 'animales', 'domésticos', 'muy', 'populares', '.'],\n",
       "  ['Los', 'gatos', 'son', 'animales', 'domésticos', 'muy', 'populares', '.']),\n",
       " (['Me', 'gusta', 'caminar', 'por', 'el', 'parque', 'en', 'las', 'mañanas.'],\n",
       "  ['Me',\n",
       "   'gusta',\n",
       "   'caminar',\n",
       "   'por',\n",
       "   'el',\n",
       "   'parque',\n",
       "   'en',\n",
       "   'las',\n",
       "   'mañanas',\n",
       "   '.'],\n",
       "  ['Me',\n",
       "   'gusta',\n",
       "   'caminar',\n",
       "   'por',\n",
       "   'el',\n",
       "   'parque',\n",
       "   'en',\n",
       "   'las',\n",
       "   'mañanas',\n",
       "   '.']),\n",
       " (['María',\n",
       "   'estaba',\n",
       "   'comprando',\n",
       "   'verduras',\n",
       "   'frescas',\n",
       "   'en',\n",
       "   'el',\n",
       "   'mercado.'],\n",
       "  ['María',\n",
       "   'estaba',\n",
       "   'comprando',\n",
       "   'verduras',\n",
       "   'frescas',\n",
       "   'en',\n",
       "   'el',\n",
       "   'mercado',\n",
       "   '.'],\n",
       "  ['María',\n",
       "   'estaba',\n",
       "   'comprando',\n",
       "   'verduras',\n",
       "   'frescas',\n",
       "   'en',\n",
       "   'el',\n",
       "   'mercado',\n",
       "   '.']),\n",
       " (['La',\n",
       "   'tecnología',\n",
       "   'avanza',\n",
       "   'rápidamente',\n",
       "   'y',\n",
       "   'nos',\n",
       "   'facilita',\n",
       "   'la',\n",
       "   'vida.'],\n",
       "  ['La',\n",
       "   'tecnología',\n",
       "   'avanza',\n",
       "   'rápidamente',\n",
       "   'y',\n",
       "   'nos',\n",
       "   'facilita',\n",
       "   'la',\n",
       "   'vida',\n",
       "   '.'],\n",
       "  ['La',\n",
       "   'tecnología',\n",
       "   'avanza',\n",
       "   'rápidamente',\n",
       "   'y',\n",
       "   'nos',\n",
       "   'facilita',\n",
       "   'la',\n",
       "   'vida',\n",
       "   '.']),\n",
       " (['Los', 'estudiantes', 'estudian', 'para', 'sus', 'exámenes', 'finales.'],\n",
       "  ['Los',\n",
       "   'estudiantes',\n",
       "   'estudian',\n",
       "   'para',\n",
       "   'sus',\n",
       "   'exámenes',\n",
       "   'finales',\n",
       "   '.'],\n",
       "  ['Los',\n",
       "   'estudiantes',\n",
       "   'estudian',\n",
       "   'para',\n",
       "   'sus',\n",
       "   'exámenes',\n",
       "   'finales',\n",
       "   '.']),\n",
       " (['Pedro',\n",
       "   'corre',\n",
       "   'todos',\n",
       "   'los',\n",
       "   'días',\n",
       "   'para',\n",
       "   'mantenerse',\n",
       "   'en',\n",
       "   'forma.'],\n",
       "  ['Pedro',\n",
       "   'corre',\n",
       "   'todos',\n",
       "   'los',\n",
       "   'días',\n",
       "   'para',\n",
       "   'mantenerse',\n",
       "   'en',\n",
       "   'forma',\n",
       "   '.'],\n",
       "  ['Pedro',\n",
       "   'corre',\n",
       "   'todos',\n",
       "   'los',\n",
       "   'días',\n",
       "   'para',\n",
       "   'mantenerse',\n",
       "   'en',\n",
       "   'forma',\n",
       "   '.']),\n",
       " (['La',\n",
       "   'lectura',\n",
       "   'es',\n",
       "   'un',\n",
       "   'hábito',\n",
       "   'saludable',\n",
       "   'que',\n",
       "   'todos',\n",
       "   'deberían',\n",
       "   'practicar.'],\n",
       "  ['La',\n",
       "   'lectura',\n",
       "   'es',\n",
       "   'un',\n",
       "   'hábito',\n",
       "   'saludable',\n",
       "   'que',\n",
       "   'todos',\n",
       "   'deberían',\n",
       "   'practicar',\n",
       "   '.'],\n",
       "  ['La',\n",
       "   'lectura',\n",
       "   'es',\n",
       "   'un',\n",
       "   'hábito',\n",
       "   'saludable',\n",
       "   'que',\n",
       "   'todos',\n",
       "   'deberían',\n",
       "   'practicar',\n",
       "   '.']),\n",
       " (['Ella',\n",
       "   'encontró',\n",
       "   'un',\n",
       "   'libro',\n",
       "   'interesante',\n",
       "   'en',\n",
       "   'la',\n",
       "   'biblioteca.'],\n",
       "  ['Ella',\n",
       "   'encontró',\n",
       "   'un',\n",
       "   'libro',\n",
       "   'interesante',\n",
       "   'en',\n",
       "   'la',\n",
       "   'biblioteca',\n",
       "   '.'],\n",
       "  ['Ella',\n",
       "   'encontró',\n",
       "   'un',\n",
       "   'libro',\n",
       "   'interesante',\n",
       "   'en',\n",
       "   'la',\n",
       "   'biblioteca',\n",
       "   '.']),\n",
       " (['Los', 'niños', 'juegan', 'en', 'el', 'patio', 'durante', 'el', 'recreo.'],\n",
       "  ['Los',\n",
       "   'niños',\n",
       "   'juegan',\n",
       "   'en',\n",
       "   'el',\n",
       "   'patio',\n",
       "   'durante',\n",
       "   'el',\n",
       "   'recreo',\n",
       "   '.'],\n",
       "  ['Los',\n",
       "   'niños',\n",
       "   'juegan',\n",
       "   'en',\n",
       "   'el',\n",
       "   'patio',\n",
       "   'durante',\n",
       "   'el',\n",
       "   'recreo',\n",
       "   '.']),\n",
       " (['El', 'clima', 'en', 'esta', 'ciudad', 'es', 'muy', 'variable.'],\n",
       "  ['El', 'clima', 'en', 'esta', 'ciudad', 'es', 'muy', 'variable', '.'],\n",
       "  ['El', 'clima', 'en', 'esta', 'ciudad', 'es', 'muy', 'variable', '.']),\n",
       " (['Los',\n",
       "   'ingenieros',\n",
       "   'diseñan',\n",
       "   'soluciones',\n",
       "   'innovadoras',\n",
       "   'para',\n",
       "   'problemas',\n",
       "   'complejos.'],\n",
       "  ['Los',\n",
       "   'ingenieros',\n",
       "   'diseñan',\n",
       "   'soluciones',\n",
       "   'innovadoras',\n",
       "   'para',\n",
       "   'problemas',\n",
       "   'complejos',\n",
       "   '.'],\n",
       "  ['Los',\n",
       "   'ingenieros',\n",
       "   'diseñan',\n",
       "   'soluciones',\n",
       "   'innovadoras',\n",
       "   'para',\n",
       "   'problemas',\n",
       "   'complejos',\n",
       "   '.']),\n",
       " (['La', 'música', 'clásica', 'tiene', 'un', 'efecto', 'relajante.'],\n",
       "  ['La', 'música', 'clásica', 'tiene', 'un', 'efecto', 'relajante', '.'],\n",
       "  ['La', 'música', 'clásica', 'tiene', 'un', 'efecto', 'relajante', '.']),\n",
       " (['Los',\n",
       "   'turistas',\n",
       "   'visitan',\n",
       "   'la',\n",
       "   'ciudad',\n",
       "   'para',\n",
       "   'disfrutar',\n",
       "   'de',\n",
       "   'su',\n",
       "   'cultura',\n",
       "   'y',\n",
       "   'gastronomía.'],\n",
       "  ['Los',\n",
       "   'turistas',\n",
       "   'visitan',\n",
       "   'la',\n",
       "   'ciudad',\n",
       "   'para',\n",
       "   'disfrutar',\n",
       "   'de',\n",
       "   'su',\n",
       "   'cultura',\n",
       "   'y',\n",
       "   'gastronomía',\n",
       "   '.'],\n",
       "  ['Los',\n",
       "   'turistas',\n",
       "   'visitan',\n",
       "   'la',\n",
       "   'ciudad',\n",
       "   'para',\n",
       "   'disfrutar',\n",
       "   'de',\n",
       "   'su',\n",
       "   'cultura',\n",
       "   'y',\n",
       "   'gastronomía',\n",
       "   '.']),\n",
       " (['Estoy',\n",
       "   'aprendiendo',\n",
       "   'a',\n",
       "   'cocinar',\n",
       "   'platos',\n",
       "   'típicos',\n",
       "   'de',\n",
       "   'mi',\n",
       "   'país.'],\n",
       "  ['Estoy',\n",
       "   'aprendiendo',\n",
       "   'a',\n",
       "   'cocinar',\n",
       "   'platos',\n",
       "   'típicos',\n",
       "   'de',\n",
       "   'mi',\n",
       "   'país',\n",
       "   '.'],\n",
       "  ['Estoy',\n",
       "   'aprendiendo',\n",
       "   'a',\n",
       "   'cocinar',\n",
       "   'platos',\n",
       "   'típicos',\n",
       "   'de',\n",
       "   'mi',\n",
       "   'país',\n",
       "   '.']),\n",
       " (['El', 'tren', 'llegó', 'a', 'tiempo', 'a', 'la', 'estación.'],\n",
       "  ['El', 'tren', 'llegó', 'a', 'tiempo', 'a', 'la', 'estación', '.'],\n",
       "  ['El', 'tren', 'llegó', 'a', 'tiempo', 'a', 'la', 'estación', '.']),\n",
       " (['Los', 'pájaros', 'cantan', 'al', 'amanecer.'],\n",
       "  ['Los', 'pájaros', 'cantan', 'al', 'amanecer', '.'],\n",
       "  ['Los', 'pájaros', 'cantan', 'al', 'amanecer', '.']),\n",
       " (['El',\n",
       "   'nuevo',\n",
       "   'proyecto',\n",
       "   'de',\n",
       "   'construcción',\n",
       "   'comenzará',\n",
       "   'la',\n",
       "   'próxima',\n",
       "   'semana.'],\n",
       "  ['El',\n",
       "   'nuevo',\n",
       "   'proyecto',\n",
       "   'de',\n",
       "   'construcción',\n",
       "   'comenzará',\n",
       "   'la',\n",
       "   'próxima',\n",
       "   'semana',\n",
       "   '.'],\n",
       "  ['El',\n",
       "   'nuevo',\n",
       "   'proyecto',\n",
       "   'de',\n",
       "   'construcción',\n",
       "   'comenzará',\n",
       "   'la',\n",
       "   'próxima',\n",
       "   'semana',\n",
       "   '.']),\n",
       " (['Ayer',\n",
       "   'fuimos',\n",
       "   'al',\n",
       "   'cine',\n",
       "   'y',\n",
       "   'vimos',\n",
       "   'una',\n",
       "   'película',\n",
       "   'emocionante.'],\n",
       "  ['Ayer',\n",
       "   'fuimos',\n",
       "   'al',\n",
       "   'cine',\n",
       "   'y',\n",
       "   'vimos',\n",
       "   'una',\n",
       "   'película',\n",
       "   'emocionante',\n",
       "   '.'],\n",
       "  ['Ayer',\n",
       "   'fuimos',\n",
       "   'al',\n",
       "   'cine',\n",
       "   'y',\n",
       "   'vimos',\n",
       "   'una',\n",
       "   'película',\n",
       "   'emocionante',\n",
       "   '.']),\n",
       " (['Los',\n",
       "   'árboles',\n",
       "   'del',\n",
       "   'parque',\n",
       "   'están',\n",
       "   'floreciendo',\n",
       "   'en',\n",
       "   'primavera.'],\n",
       "  ['Los',\n",
       "   'árboles',\n",
       "   'del',\n",
       "   'parque',\n",
       "   'están',\n",
       "   'floreciendo',\n",
       "   'en',\n",
       "   'primavera',\n",
       "   '.'],\n",
       "  ['Los',\n",
       "   'árboles',\n",
       "   'del',\n",
       "   'parque',\n",
       "   'están',\n",
       "   'floreciendo',\n",
       "   'en',\n",
       "   'primavera',\n",
       "   '.']),\n",
       " (['La',\n",
       "   'comunicación',\n",
       "   'efectiva',\n",
       "   'es',\n",
       "   'clave',\n",
       "   'en',\n",
       "   'cualquier',\n",
       "   'relación.'],\n",
       "  ['La',\n",
       "   'comunicación',\n",
       "   'efectiva',\n",
       "   'es',\n",
       "   'clave',\n",
       "   'en',\n",
       "   'cualquier',\n",
       "   'relación',\n",
       "   '.'],\n",
       "  ['La',\n",
       "   'comunicación',\n",
       "   'efectiva',\n",
       "   'es',\n",
       "   'clave',\n",
       "   'en',\n",
       "   'cualquier',\n",
       "   'relación',\n",
       "   '.'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargue el archivo csv\n",
    "\n",
    "df=pd.read_csv(\"C:/Users/YESENIA/Desktop/Taller1/backend/inputs/inputs.csv\")\n",
    "# aplique los tokenizadores a las oraciones \n",
    "\n",
    "ws_tk = WhitespaceTokenizer()\n",
    "[ ws_tk.tokenize(st) for st in df['oracion']]\n",
    "wp_tk = WordPunctTokenizer()\n",
    "[ wp_tk.tokenize(st) for st in df['oracion']]\n",
    "tb_tk = TreebankWordTokenizer()\n",
    "[ tb_tk.tokenize(st) for st in df['oracion']]\n",
    "\n",
    "\n",
    "[ (ws_tk.tokenize(st), wp_tk.tokenize(st), tb_tk.tokenize(st)) for st in df['oracion']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_file = \"/Users/YESENIA/Desktop/Taller1/backend/models/model1.pkl\"\n",
    "m2_file = \"/Users/YESENIA/Desktop/Taller1/backend/models/model2.pkl\"\n",
    "m3_file = \"/Users/YESENIA/Desktop/Taller1/backend/models/model3.pkl\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/YESENIA/Desktop/Taller1/backend/models/model3.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving WhitespaceTokenizer\n",
    "joblib.dump(ws_tk, m1_file)\n",
    "# saving WordPunctTokenizer\n",
    "joblib.dump(wp_tk, m2_file)\n",
    "# saving TreebackTokenizer\n",
    "joblib.dump(tb_tk, m3_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['los', 'gat', 'son', 'animal', 'domest', 'muy', 'popular', '.'], ['me', 'gust', 'camin', 'por', 'el', 'parqu', 'en', 'las', 'mañan', '.'], ['mar', 'estab', 'compr', 'verdur', 'fresc', 'en', 'el', 'merc', '.'], ['la', 'tecnolog', 'avanz', 'rapid', 'y', 'nos', 'facilit', 'la', 'vid', '.'], ['los', 'estudi', 'estudi', 'par', 'sus', 'examen', 'final', '.'], ['pedr', 'corr', 'tod', 'los', 'dias', 'par', 'manten', 'en', 'form', '.'], ['la', 'lectur', 'es', 'un', 'habit', 'salud', 'que', 'tod', 'deb', 'practic', '.'], ['ella', 'encontr', 'un', 'libr', 'interes', 'en', 'la', 'bibliotec', '.'], ['los', 'niñ', 'jueg', 'en', 'el', 'pati', 'durant', 'el', 'recre', '.'], ['el', 'clim', 'en', 'esta', 'ciud', 'es', 'muy', 'variabl', '.'], ['los', 'ingenier', 'diseñ', 'solucion', 'innov', 'par', 'problem', 'complej', '.'], ['la', 'music', 'clasic', 'tien', 'un', 'efect', 'relaj', '.'], ['los', 'turist', 'visit', 'la', 'ciud', 'par', 'disfrut', 'de', 'su', 'cultur', 'y', 'gastronom', '.'], ['estoy', 'aprend', 'a', 'cocin', 'plat', 'tipic', 'de', 'mi', 'pais', '.'], ['el', 'tren', 'lleg', 'a', 'tiemp', 'a', 'la', 'estacion', '.'], ['los', 'pajar', 'cant', 'al', 'amanec', '.'], ['el', 'nuev', 'proyect', 'de', 'construccion', 'comenz', 'la', 'proxim', 'seman', '.'], ['ayer', 'fuim', 'al', 'cin', 'y', 'vim', 'una', 'pelicul', 'emocion', '.'], ['los', 'arbol', 'del', 'parqu', 'estan', 'florec', 'en', 'primaver', '.'], ['la', 'comun', 'efect', 'es', 'clav', 'en', 'cualqui', 'relacion', '.']]\n"
     ]
    }
   ],
   "source": [
    "# actividad 2 punto 1\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "sent_tokenization = [wp_tk.tokenize(st) for st in df['oracion']]\n",
    "stemmed = [ [stemmer.stem(a_token) for a_token in a_sentence] for a_sentence in sent_tokenization]\n",
    "\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\YESENIA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Los', 'gatos', 'son', 'animales', 'domésticos', 'muy', 'populares', '.'], ['Me', 'gusta', 'caminar', 'por', 'el', 'parque', 'en', 'la', 'mañanas', '.'], ['María', 'estaba', 'comprando', 'verduras', 'frescas', 'en', 'el', 'mercado', '.'], ['La', 'tecnología', 'avanza', 'rápidamente', 'y', 'no', 'facilita', 'la', 'vida', '.'], ['Los', 'estudiantes', 'estudian', 'para', 'sus', 'exámenes', 'finale', '.'], ['Pedro', 'corre', 'todos', 'los', 'días', 'para', 'mantenerse', 'en', 'forma', '.'], ['La', 'lectura', 'e', 'un', 'hábito', 'saludable', 'que', 'todos', 'deberían', 'practicar', '.'], ['Ella', 'encontró', 'un', 'libro', 'interesante', 'en', 'la', 'biblioteca', '.'], ['Los', 'niños', 'juegan', 'en', 'el', 'patio', 'durante', 'el', 'recreo', '.'], ['El', 'clima', 'en', 'esta', 'ciudad', 'e', 'muy', 'variable', '.'], ['Los', 'ingenieros', 'diseñan', 'soluciones', 'innovadoras', 'para', 'problemas', 'complejos', '.'], ['La', 'música', 'clásica', 'tiene', 'un', 'efecto', 'relajante', '.'], ['Los', 'turistas', 'visitan', 'la', 'ciudad', 'para', 'disfrutar', 'de', 'su', 'cultura', 'y', 'gastronomía', '.'], ['Estoy', 'aprendiendo', 'a', 'cocinar', 'plato', 'típicos', 'de', 'mi', 'país', '.'], ['El', 'tren', 'llegó', 'a', 'tiempo', 'a', 'la', 'estación', '.'], ['Los', 'pájaros', 'cantan', 'al', 'amanecer', '.'], ['El', 'nuevo', 'proyecto', 'de', 'construcción', 'comenzará', 'la', 'próxima', 'semana', '.'], ['Ayer', 'fuimos', 'al', 'cine', 'y', 'vimos', 'una', 'película', 'emocionante', '.'], ['Los', 'árboles', 'del', 'parque', 'están', 'floreciendo', 'en', 'primavera', '.'], ['La', 'comunicación', 'efectiva', 'e', 'clave', 'en', 'cualquier', 'relación', '.']]\n"
     ]
    }
   ],
   "source": [
    "# actividad 2 punto 2\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "sent_tokenization = [wp_tk.tokenize(st) for st in df['oracion']]\n",
    "lemmatized = [ [lemm.lemmatize(a_token) for a_token in a_sentence] for a_sentence in sent_tokenization]\n",
    "\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YESENIA\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 384kB [00:00, 24.2MB/s]                    \n",
      "2024-06-28 09:46:42 INFO: Downloaded file to C:\\Users\\YESENIA\\stanza_resources\\resources.json\n",
      "2024-06-28 09:46:42 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2024-06-28 09:46:47 INFO: File exists: C:\\Users\\YESENIA\\stanza_resources\\es\\default.zip\n",
      "2024-06-28 09:46:54 INFO: Finished downloading models and saved to C:\\Users\\YESENIA\\stanza_resources\n",
      "2024-06-28 09:46:54 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 384kB [00:00, 10.1MB/s]                    \n",
      "2024-06-28 09:46:54 INFO: Downloaded file to C:\\Users\\YESENIA\\stanza_resources\\resources.json\n",
      "2024-06-28 09:46:55 INFO: Loading these models for language: es (Spanish):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-06-28 09:46:55 INFO: Using device: cpu\n",
      "2024-06-28 09:46:55 INFO: Loading: tokenize\n",
      "2024-06-28 09:46:58 INFO: Loading: mwt\n",
      "2024-06-28 09:46:58 INFO: Loading: pos\n",
      "2024-06-28 09:46:58 INFO: Loading: lemma\n",
      "2024-06-28 09:46:59 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# actividad 2 punto 2\n",
    "import stanza\n",
    "stanza.download(\"es\")\n",
    "process= stanza.Pipeline(lang=\"es\", processors='tokenize,mwt,pos,lemma')\n",
    "docs = [ process(st) for st in df['oracion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Los', 'el'),\n",
       " ('gatos', 'gato'),\n",
       " ('son', 'ser'),\n",
       " ('animales', 'animal'),\n",
       " ('domésticos', 'doméstico'),\n",
       " ('muy', 'mucho'),\n",
       " ('populares', 'popular'),\n",
       " ('.', '.'),\n",
       " ('Me', 'yo'),\n",
       " ('gusta', 'gustar'),\n",
       " ('caminar', 'caminar'),\n",
       " ('por', 'por'),\n",
       " ('el', 'el'),\n",
       " ('parque', 'parque'),\n",
       " ('en', 'en'),\n",
       " ('las', 'el'),\n",
       " ('mañanas', 'mañana'),\n",
       " ('.', '.'),\n",
       " ('María', 'María'),\n",
       " ('estaba', 'estar'),\n",
       " ('comprando', 'comprar'),\n",
       " ('verduras', 'verdura'),\n",
       " ('frescas', 'fresco'),\n",
       " ('en', 'en'),\n",
       " ('el', 'el'),\n",
       " ('mercado', 'mercado'),\n",
       " ('.', '.'),\n",
       " ('La', 'el'),\n",
       " ('tecnología', 'tecnología'),\n",
       " ('avanza', 'avanzar'),\n",
       " ('rápidamente', 'rápidamente'),\n",
       " ('y', 'y'),\n",
       " ('nos', 'yo'),\n",
       " ('facilita', 'facilitar'),\n",
       " ('la', 'el'),\n",
       " ('vida', 'vida'),\n",
       " ('.', '.'),\n",
       " ('Los', 'el'),\n",
       " ('estudiantes', 'estudiante'),\n",
       " ('estudian', 'estudiar'),\n",
       " ('para', 'para'),\n",
       " ('sus', 'su'),\n",
       " ('exámenes', 'exámen'),\n",
       " ('finales', 'final'),\n",
       " ('.', '.'),\n",
       " ('Pedro', 'pedro'),\n",
       " ('corre', 'correr'),\n",
       " ('todos', 'todo'),\n",
       " ('los', 'el'),\n",
       " ('días', 'día'),\n",
       " ('para', 'para'),\n",
       " ('mantener', 'mantener'),\n",
       " ('se', 'él'),\n",
       " ('en', 'en'),\n",
       " ('forma', 'forma'),\n",
       " ('.', '.'),\n",
       " ('La', 'el'),\n",
       " ('lectura', 'lectura'),\n",
       " ('es', 'ser'),\n",
       " ('un', 'uno'),\n",
       " ('hábito', 'hábito'),\n",
       " ('saludable', 'saludable'),\n",
       " ('que', 'que'),\n",
       " ('todos', 'todo'),\n",
       " ('deberían', 'deber'),\n",
       " ('practicar', 'practicar'),\n",
       " ('.', '.'),\n",
       " ('Ella', 'él'),\n",
       " ('encontró', 'encontrar'),\n",
       " ('un', 'uno'),\n",
       " ('libro', 'libro'),\n",
       " ('interesante', 'interesante'),\n",
       " ('en', 'en'),\n",
       " ('la', 'el'),\n",
       " ('biblioteca', 'biblioteca'),\n",
       " ('.', '.'),\n",
       " ('Los', 'el'),\n",
       " ('niños', 'niño'),\n",
       " ('juegan', 'jugar'),\n",
       " ('en', 'en'),\n",
       " ('el', 'el'),\n",
       " ('patio', 'patio'),\n",
       " ('durante', 'durante'),\n",
       " ('el', 'el'),\n",
       " ('recreo', 'recreo'),\n",
       " ('.', '.'),\n",
       " ('El', 'el'),\n",
       " ('clima', 'clima'),\n",
       " ('en', 'en'),\n",
       " ('esta', 'este'),\n",
       " ('ciudad', 'ciudad'),\n",
       " ('es', 'ser'),\n",
       " ('muy', 'mucho'),\n",
       " ('variable', 'variable'),\n",
       " ('.', '.'),\n",
       " ('Los', 'el'),\n",
       " ('ingenieros', 'ingeniero'),\n",
       " ('diseñan', 'diseñar'),\n",
       " ('soluciones', 'solución'),\n",
       " ('innovadoras', 'innovador'),\n",
       " ('para', 'para'),\n",
       " ('problemas', 'problema'),\n",
       " ('complejos', 'complejo'),\n",
       " ('.', '.'),\n",
       " ('La', 'el'),\n",
       " ('música', 'música'),\n",
       " ('clásica', 'clásico'),\n",
       " ('tiene', 'tener'),\n",
       " ('un', 'uno'),\n",
       " ('efecto', 'efecto'),\n",
       " ('relajante', 'relajante'),\n",
       " ('.', '.'),\n",
       " ('Los', 'el'),\n",
       " ('turistas', 'turista'),\n",
       " ('visitan', 'visitar'),\n",
       " ('la', 'el'),\n",
       " ('ciudad', 'ciudad'),\n",
       " ('para', 'para'),\n",
       " ('disfrutar', 'disfrutar'),\n",
       " ('de', 'de'),\n",
       " ('su', 'su'),\n",
       " ('cultura', 'cultura'),\n",
       " ('y', 'y'),\n",
       " ('gastronomía', 'gastronomía'),\n",
       " ('.', '.'),\n",
       " ('Estoy', 'estar'),\n",
       " ('aprendiendo', 'aprender'),\n",
       " ('a', 'a'),\n",
       " ('cocinar', 'cocinar'),\n",
       " ('platos', 'plato'),\n",
       " ('típicos', 'típico'),\n",
       " ('de', 'de'),\n",
       " ('mi', 'mi'),\n",
       " ('país', 'país'),\n",
       " ('.', '.'),\n",
       " ('El', 'el'),\n",
       " ('tren', 'tren'),\n",
       " ('llegó', 'llegar'),\n",
       " ('a', 'a'),\n",
       " ('tiempo', 'tiempo'),\n",
       " ('a', 'a'),\n",
       " ('la', 'el'),\n",
       " ('estación', 'estación'),\n",
       " ('.', '.'),\n",
       " ('Los', 'el'),\n",
       " ('pájaros', 'pájaro'),\n",
       " ('cantan', 'cantar'),\n",
       " ('a', 'a'),\n",
       " ('el', 'el'),\n",
       " ('amanecer', 'amanecer'),\n",
       " ('.', '.'),\n",
       " ('El', 'el'),\n",
       " ('nuevo', 'nuevo'),\n",
       " ('proyecto', 'proyecto'),\n",
       " ('de', 'de'),\n",
       " ('construcción', 'construcción'),\n",
       " ('comenzará', 'comenzar'),\n",
       " ('la', 'el'),\n",
       " ('próxima', 'próximo'),\n",
       " ('semana', 'semana'),\n",
       " ('.', '.'),\n",
       " ('Ayer', 'ayer'),\n",
       " ('fuimos', 'ir'),\n",
       " ('a', 'a'),\n",
       " ('el', 'el'),\n",
       " ('cine', 'cine'),\n",
       " ('y', 'y'),\n",
       " ('vimos', 'ver'),\n",
       " ('una', 'uno'),\n",
       " ('película', 'película'),\n",
       " ('emocionante', 'emocionante'),\n",
       " ('.', '.'),\n",
       " ('Los', 'el'),\n",
       " ('árboles', 'árbol'),\n",
       " ('de', 'de'),\n",
       " ('el', 'el'),\n",
       " ('parque', 'parque'),\n",
       " ('están', 'estar'),\n",
       " ('floreciendo', 'florecir'),\n",
       " ('en', 'en'),\n",
       " ('primavera', 'primavera'),\n",
       " ('.', '.'),\n",
       " ('La', 'el'),\n",
       " ('comunicación', 'comunicación'),\n",
       " ('efectiva', 'efectivo'),\n",
       " ('es', 'ser'),\n",
       " ('clave', 'clave'),\n",
       " ('en', 'en'),\n",
       " ('cualquier', 'cualquiera'),\n",
       " ('relación', 'relación'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences= [a_doc.sentences for a_doc in docs]\n",
    "lst_words = [words for a_sentence in sentences for words in a_sentence[0].words]\n",
    "[(a_word.text, a_word.lemma) for a_word  in lst_words]\n",
    "## result=[ [(a_word.text, a_word.lemma)] for sent in doc for a_word in sent]\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/YESENIA/Desktop/Taller1/backend/models/model5.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actividad 2 punto 3\n",
    "joblib.dump(stemmer,\"C:/Users/YESENIA/Desktop/Taller1/backend/models/model4.pkl\")\n",
    "joblib.dump(lemm,\"C:/Users/YESENIA/Desktop/Taller1/backend/models/model5.pkl\")\n",
    "\n",
    "#C:\\Users\\YESENIA\\Desktop\\Taller1\\backend\\models\n",
    "#C:\\Users\\YESENIA\\Desktop\\Taller1\\backend\\models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
